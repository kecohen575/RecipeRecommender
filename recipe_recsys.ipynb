{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee8bcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcc0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load interaction splits\n",
    "train_df = pd.read_csv(\"dataset/interactions_train.csv\")\n",
    "val_df = pd.read_csv(\"dataset/interactions_validation.csv\")\n",
    "test_df = pd.read_csv(\"dataset/interactions_test.csv\")\n",
    "\n",
    "# Optional: load raw metadata for future use\n",
    "raw_recipes = pd.read_csv(\"dataset/RAW_recipes.csv\")\n",
    "raw_interactions = pd.read_csv(\"dataset/RAW_interactions.csv\")\n",
    "\n",
    "# Preprocessed embeddings (not needed yet)\n",
    "pp_users = pd.read_csv(\"dataset/PP_users.csv\")\n",
    "pp_recipes = pd.read_csv(\"dataset/PP_recipes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e9a2e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b3ca47",
   "metadata": {},
   "source": [
    "## Interaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b80138",
   "metadata": {},
   "source": [
    "### Distribution of Recipe Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac66d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "train_df['rating'].hist(bins=6, edgecolor='black')\n",
    "plt.title(\"Distribution of Recipe Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef70ca",
   "metadata": {},
   "source": [
    "The distribution of ratings in the dataset is heavily skewed toward the positive end of the scale. Ratings of 4 and 5 stars dominate the dataset, with 5-star ratings forming a noticeable spike. This suggests that users tend to leave high ratings for recipes they try, which is consistent with user behavior on recipe platforms—people often cook recipes they expect to enjoy and are more motivated to provide feedback when the outcome is favorable.\n",
    "\n",
    "Interestingly, while ratings of 1 and 2 stars are rare, the number of 0-star ratings is noticeably higher than both 1 and 2 stars. In fact, 0-star ratings are closer in frequency to 3-star ratings than to the lower end of the scale. This suggests that users may assign a 0 rating deliberately to express strong dissatisfaction, rather than using intermediate low values like 1 or 2. As a result, the distribution forms a somewhat smooth curve from 1–5, but with a bimodal shape at the extremes: a large concentration at 5 stars, and an unnatural bump at 0.\n",
    "\n",
    "This behavior has important implications for model design:\n",
    "\n",
    "- The dominance of high ratings means that predicting the mean rating is not a useful baseline—a trivial model could appear accurate without making meaningful recommendations.\n",
    "\n",
    "- Because the data is not evenly distributed across the rating scale, metrics like MSE can be misleading.\n",
    "\n",
    "- Instead, ranking-based evaluation metrics (e.g., Precision@K, Recall@K, MRR) are more appropriate for this dataset, as they focus on how well a model orders preferred recipes rather than how close it gets to numeric ratings.\n",
    "\n",
    "Overall, this positive and somewhat polarized rating behavior provides a strong motivation for using ranking-based recommender models rather than simple rating prediction approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39492f8f",
   "metadata": {},
   "source": [
    "### Distribution of Ratings per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66328e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_counts = train_df.groupby('u').size()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "user_counts.hist(bins=50, log=True, edgecolor='black')\n",
    "plt.title(\"Number of Ratings per User (log scale)\")\n",
    "plt.xlabel(\"Ratings per User\")\n",
    "plt.ylabel(\"User Count (log)\")\n",
    "plt.show()\n",
    "\n",
    "user_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4335f49",
   "metadata": {},
   "source": [
    "The distribution of user activity displays an extreme long-tail pattern. While a small number of users have rated hundreds or even thousands of recipes, the vast majority have contributed only a handful of ratings. This is typical of user-generated content platforms: most users interact casually, whereas a small subset of so-called power users engage extensively.\n",
    "\n",
    "Because the y-axis is plotted on a logarithmic scale, we can clearly see the steep drop-off in participation. The dataset contains many users who have rated fewer than 10 recipes, and progressively fewer users as the number of ratings increases. Only a tiny fraction exceed 1,000 ratings, and some appear to rate over 6,000 recipes, indicating extremely active contributors.\n",
    "\n",
    "This imbalance has meaningful implications for model training:\n",
    "\n",
    "- Sparse user histories make it difficult for the model to learn stable preference patterns for many users.\n",
    "\n",
    "- Power users may disproportionately influence learned embeddings if the model is not properly regularized.\n",
    "\n",
    "- Techniques such as latent factor models, which generalize user preferences through shared structure, are well-suited to handle this kind of interaction sparsity.\n",
    "\n",
    "Overall, the user activity distribution underscores the importance of collaborative approaches that leverage patterns across users, rather than relying solely on individual histories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b9c00e",
   "metadata": {},
   "source": [
    "### Distribution of Ratings per Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce743fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = train_df.groupby('i').size()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "item_counts.hist(bins=50, log=True, edgecolor='black')\n",
    "plt.title(\"Number of Ratings per Recipe (log scale)\")\n",
    "plt.xlabel(\"Ratings per Recipe\")\n",
    "plt.ylabel(\"Recipe Count (log)\")\n",
    "plt.show()\n",
    "\n",
    "item_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67fc68e",
   "metadata": {},
   "source": [
    "The distribution of recipe popularity shows an even stronger long-tail effect than user activity. Most recipes receive very few ratings, while a small number accumulate hundreds or even over 1,000 ratings. Once again, the use of a logarithmic scale reveals this imbalance clearly: a large proportion of recipes appear only once or twice in the dataset, whereas only a handful receive widespread attention.\n",
    "\n",
    "This structure is typical of domains with expansive item catalogs, where new or niche items receive little engagement. For recommender systems, this creates a challenge known as the item cold-start problem: many recipes lack enough historical data for the model to learn their characteristics well.\n",
    "\n",
    "From a modeling standpoint, this motivates the use of techniques that incorporate additional recipe features—such as ingredients, cooking time, tags, or nutritional attributes—to supplement sparse interaction histories. Later extensions to collaborative filtering or factorization models can leverage this metadata to improve recommendations for less frequently rated recipes.\n",
    "\n",
    "In summary, the long-tail nature of recipe ratings demonstrates both the difficulty and necessity of a recommendation model capable of generalizing from limited item-specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490df57",
   "metadata": {},
   "source": [
    "### Sparsity of the Interaction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = train_df['u'].nunique()\n",
    "n_items = train_df['i'].nunique()\n",
    "n_interactions = len(train_df)\n",
    "\n",
    "sparsity = 1 - n_interactions / (n_users * n_items)\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c23fd",
   "metadata": {},
   "source": [
    "The combination of a large number of users, a large number of recipes, and relatively few observed interactions produces an interaction matrix that is extremely sparse. In other words, the vast majority of possible user–recipe pairs have no recorded rating. High sparsity is characteristic of recommendation datasets and directly motivates the use of models such as collaborative filtering and matrix factorization, which exploit shared patterns across users and items to predict missing entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa6cfb",
   "metadata": {},
   "source": [
    "## Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dd2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_recipes.info()\n",
    "raw_recipes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fda928",
   "metadata": {},
   "source": [
    "### Distribution of Ingredient Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "raw_recipes['n_ingredients'].hist(bins=30, edgecolor='black')\n",
    "plt.title(\"Distribution of Ingredient Counts\")\n",
    "plt.xlabel(\"Number of Ingredients\")\n",
    "plt.ylabel(\"Recipe Count\")\n",
    "plt.show()\n",
    "\n",
    "raw_recipes['n_ingredients'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f58ac",
   "metadata": {},
   "source": [
    "The number of ingredients per recipe follows a moderately right-skewed distribution. Most recipes require a manageable set of ingredients, with the majority falling between 6 and 11 ingredients. The median of 9 ingredients aligns with this visual impression, suggesting that typical recipes in the dataset are neither overly simple nor excessively complex.\n",
    "\n",
    "Recipes with fewer than 5 ingredients are relatively uncommon, indicating that most dishes involve a moderate combination of components rather than minimalist, two- or three-ingredient preparations. At the other end of the spectrum, a small number of recipes contain 20 or more ingredients, with the maximum reaching 43, representing highly elaborate dishes that demand substantial preparation and planning.\n",
    "\n",
    "This distribution provides several useful insights for recommendation strategies:\n",
    "\n",
    "- The ingredient count reflects a dimension of recipe complexity that may influence user preference. Some users may gravitate toward simple, quick recipes, while others enjoy more involved cooking projects.\n",
    "\n",
    "- The presence of many recipes clustered around similar ingredient counts suggests room for latent structure in modeling item similarity.\n",
    "\n",
    "- Given the long tail of high-ingredient recipes, integrating ingredient-based metadata could be valuable for improving recommendations in cold-start contexts for less frequently rated recipes.\n",
    "\n",
    "Overall, the ingredient counts provide a quantitative lens into recipe complexity and reinforce the potential importance of metadata in augmenting collaborative filtering models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb70916",
   "metadata": {},
   "source": [
    "### Distribution of Cooking Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a344f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_minutes = raw_recipes['minutes']\n",
    "valid_minutes = valid_minutes[valid_minutes > 0]  # remove zero-minute anomalies\n",
    "\n",
    "MAX_REASONABLE_MINUTES = 7 * 24 * 60  # 7 days\n",
    "valid_minutes = valid_minutes[valid_minutes <= MAX_REASONABLE_MINUTES]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(valid_minutes, bins=100, edgecolor='black', log=True)\n",
    "plt.title(\"Distribution of Cooking Times (log scale, 7-day cutoff)\")\n",
    "plt.xlabel(\"Minutes\")\n",
    "plt.ylabel(\"Recipe Count (log)\")\n",
    "plt.show()\n",
    "\n",
    "valid_minutes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd72a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_minutes = raw_recipes['minutes']\n",
    "valid_minutes = valid_minutes[valid_minutes > 0]  # remove zero-minute anomalies\n",
    "\n",
    "MAX_REASONABLE_MINUTES = 24 * 60  # 1 day\n",
    "valid_minutes = valid_minutes[valid_minutes <= MAX_REASONABLE_MINUTES]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(valid_minutes, bins=100, edgecolor='black', log=True)\n",
    "plt.title(\"Distribution of Cooking Times (log scale, 1-day cutoff)\")\n",
    "plt.xlabel(\"Minutes\")\n",
    "plt.ylabel(\"Recipe Count (log)\")\n",
    "plt.show()\n",
    "\n",
    "valid_minutes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a05d493",
   "metadata": {},
   "source": [
    "The distribution of cooking times exhibits a clear long-tailed structure, with most recipes requiring under an hour to prepare. The median cooking time is 40 minutes, and 75% of recipes complete within 65 minutes, indicating that the dataset is dominated by everyday dishes rather than lengthy, multi-day preparations.\n",
    "\n",
    "However, the histogram also reveals a striking pattern: distinct spikes at regular time intervals such as 20, 40, 60, 120, 1440, and 2880 minutes. These peaks do not reflect natural variation in cooking durations; instead, they suggest that Food.com's interface offers preset time categories rather than free-form numeric entry. Recipe creators likely selected from options such as \"30 minutes or less,\" \"1–2 hours,\" or \"overnight,\" which the dataset subsequently converted into exact minute values.\n",
    "\n",
    "This discretization is important for later modeling considerations:\n",
    "\n",
    "- Cooking time should not be treated as a precise continuous variable\n",
    "\n",
    "- It is best interpreted as a coarse indicator of recipe effort level\n",
    "\n",
    "- If used as a feature, it may require binning or embedding, not raw numeric scaling\n",
    "\n",
    "Overall, the cooking time distribution reinforces the idea that recipe metadata contains interpretable structure, but also highlights the importance of understanding the data collection process behind it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee5ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = valid_minutes.value_counts().sort_index() \n",
    "value_counts.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc55113",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 15, 30, 60, 120, 240, 720, 1440, 2880, 10080]\n",
    "labels = [\n",
    "    \"< 15 min\",\n",
    "    \"15-30 min\",\n",
    "    \"30-60 min\",\n",
    "    \"1-2 hours\",\n",
    "    \"2-4 hours\",\n",
    "    \"4-12 hours\",\n",
    "    \"12-24 hours\",\n",
    "    \"1-2 days\",\n",
    "    \"2-7 days\"\n",
    "]\n",
    "\n",
    "binned = pd.cut(valid_minutes, bins=bins, labels=labels, right=False)\n",
    "binned.value_counts().sort_index().plot(kind='bar', figsize=(8,4), edgecolor='black')\n",
    "\n",
    "plt.title(\"Grouped Cooking Time Categories\")\n",
    "plt.xlabel(\"Estimated Time Category\")\n",
    "plt.ylabel(\"Recipe Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327d6b1",
   "metadata": {},
   "source": [
    "This confirms that recipe cooking times are not continuous values but fall into a small number of predefined ranges. Rather than reflecting precise preparation durations, the minutes field appears to encode preset time selections from the original interface. This means cooking time should be interpreted as a coarse indicator of effort level rather than an exact numeric measurement, and treated accordingly in any downstream modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396ac5c",
   "metadata": {},
   "source": [
    "### Most Common Recipe Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a254db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stringified lists to actual Python lists\n",
    "raw_tags = raw_recipes['tags'].dropna().apply(ast.literal_eval)\n",
    "\n",
    "# Flatten the tag lists and count frequencies\n",
    "tag_counter = Counter(tag for tags in raw_tags for tag in tags)\n",
    "\n",
    "top_50 = dict(tag_counter.most_common(50))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(top_50.keys(), top_50.values(), edgecolor='black')\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.title(\"Top 50 Most Common Recipe Tags\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Tag\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542e551",
   "metadata": {},
   "source": [
    "The top 50 tags reveal that Food.com recipes are annotated with a structured and hierarchical tagging system rather than informal, user-generated keywords. Broad organizational tags such as *preparation*, *time-to-make*, and *course* dominate the dataset, reflecting how the platform categorizes recipes before more specific descriptors like ingredients, cuisines, or dietary restrictions are applied. Time-based tags (e.g., *30-minutes-or-less*, *60-minutes-or-less*) and complexity indicators (e.g., *easy*, *3-steps-or-less*) further reinforce the idea that effort level is central to how users search for and evaluate recipes. Together, these tags provide rich semantic information that can enhance recommendations—especially for new recipes with few ratings—by linking items through shared characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7eda7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f753158",
   "metadata": {},
   "source": [
    "### Ratings Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = train_df.copy()\n",
    "interactions['date'] = pd.to_datetime(interactions['date'], errors='coerce')\n",
    "\n",
    "# Aggregate counts by month\n",
    "ratings_per_month = interactions.groupby(interactions['date'].dt.to_period('M')).size()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "ratings_per_month.plot()\n",
    "plt.title(\"Number of Ratings Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Ratings Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "ratings_per_month.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a0a28",
   "metadata": {},
   "source": [
    "The number of ratings submitted to Food.com increased steadily in the early 2000s, surging sharply between 2006 and 2009 before peaking at over 10,000 ratings per month. After 2009, rating activity declined, likely due to users migrating toward newer recipe platforms and social media–driven food communities. This temporal pattern indicates that user engagement is not static—preferences, recipe trends, and platform usage all evolve over time. For a recommender system, this raises the possibility that a time-aware model could outperform a static one by accounting for changes in recipe popularity or shifts in user interests. While our initial models will treat interactions as time-independent, this trend highlights a clear path for future work: incorporating temporal dynamics to personalize recommendations based on when users interact, not just what they interact with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebf14b1",
   "metadata": {},
   "source": [
    "### Nutritional Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce97fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse calories from nutrition column (index 0 in the list)\n",
    "calories = raw_recipes['nutrition'].dropna().apply(lambda x: ast.literal_eval(x)[0])\n",
    "\n",
    "# Clip extreme values for readability (95th percentile)\n",
    "calories_clipped = calories.clip(upper=calories.quantile(0.98))\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(calories_clipped, bins=50, edgecolor='black')\n",
    "plt.title(\"Distribution of Recipe Calories (clipped at 98th percentile)\")\n",
    "plt.xlabel(\"Calories\")\n",
    "plt.ylabel(\"Recipe Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a98af1",
   "metadata": {},
   "source": [
    "The calorie distribution is distinctly right-skewed: most recipes fall between 100 and 500 calories, with progressively fewer high-calorie dishes extending into the 1,000+ calorie range. This reflects the broad range of meals on Food.com, from lighter snacks and sides to calorie-dense entrées and desserts. The shape of this distribution suggests that caloric content is a meaningful differentiator between recipe types and could influence user behavior—some users may consistently prefer lighter dishes, while others gravitate toward more indulgent options. Although our baseline recommender will ignore this information, these nutritional features provide a clear avenue for future extensions, such as health-aware or diet-constrained recommendations that personalize suggestions based not only on past ratings but also on user dietary preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047871f",
   "metadata": {},
   "source": [
    "## Interaction × Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65215f11",
   "metadata": {},
   "source": [
    "### Popularity vs Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute recipe popularity (# of ratings) and mean rating\n",
    "recipe_stats = train_df.groupby('i').agg(\n",
    "    n_ratings=('rating', 'count'),\n",
    "    avg_rating=('rating', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Optional: remove recipes with extremely few ratings, to avoid noise\n",
    "recipe_stats = recipe_stats[recipe_stats['n_ratings'] >= 5]\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(recipe_stats['n_ratings'], recipe_stats['avg_rating'], alpha=0.3)\n",
    "plt.xscale('log')  # popularity is long-tailed\n",
    "plt.xlabel(\"Number of Ratings (log scale)\")\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.title(\"Recipe Popularity vs Average Rating\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd3bc8",
   "metadata": {},
   "source": [
    "This plot illustrates how recipe popularity relates to perceived quality. Recipes with only a few ratings span the full range of possible averages—from very low to seemingly perfect scores—reflecting the high variance typical of sparse data. As the number of ratings increases, this variance collapses, and recipes converge toward a stable average of roughly 4.5 stars, which mirrors the global rating bias observed earlier. Popular recipes therefore do not become worse; rather, their ratings are more reliable because they reflect opinions from a larger and more diverse user base. In contrast, many little-reviewed recipes appear unrealistically strong due to a handful of enthusiastic reviewers. This highlights a core challenge for recommender systems: naively sorting by average rating will overemphasize niche items with inflated scores, underscoring the need for ranking-based methods or latent factor models that can account for popularity and data sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b82006",
   "metadata": {},
   "source": [
    "### Complexity vs Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14649a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = raw_recipes[['id', 'minutes', 'n_steps', 'n_ingredients']].copy()\n",
    "meta = meta.rename(columns={'id': 'recipe_id'})\n",
    "\n",
    "# Merge metadata with interactions\n",
    "df = train_df.merge(meta, on='recipe_id')\n",
    "\n",
    "# Filter out extreme time anomalies (as before)\n",
    "df = df[df['minutes'] > 0]\n",
    "df = df[df['minutes'] <= 7*24*60]  # 7 days max\n",
    "\n",
    "# Select complexity components\n",
    "features = df[['minutes', 'n_steps', 'n_ingredients']].astype(float)\n",
    "\n",
    "# Standardize each metric\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Complexity = sum of normalized components\n",
    "df['complexity'] = scaled.sum(axis=1)\n",
    "\n",
    "# Compute average rating per complexity level (bin complexity for readability)\n",
    "df['complexity_bin'] = pd.qcut(df['complexity'], q=30, duplicates='drop')\n",
    "comp_rating = df.groupby('complexity_bin')['rating'].mean().reset_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(comp_rating.index, comp_rating['rating'], marker='o')\n",
    "plt.xlabel(\"Complexity (binned quantiles)\")\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.title(\"Recipe Complexity vs Average Rating\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524dd760",
   "metadata": {},
   "source": [
    "Recipe complexity shows only a weak relationship to user satisfaction. The simplest recipes receive slightly higher ratings on average, but the effect is very small—about 0.07 stars across the entire complexity range—indicating that users do not strongly reward or penalize complexity in isolation. While there is a modest initial decline as recipes become more involved, the ratings quickly stabilize, suggesting that highly complex dishes are not necessarily perceived as better or worse, just more demanding. This minimal variation implies that complexity is not a reliable global predictor of preference. Instead, complexity may matter only at the individual level—some users consistently enjoy ambitious cooking projects, while others prefer quick meals—highlighting the need for a personalized recommender rather than a system that assumes simpler or more complex recipes are universally better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc61b44",
   "metadata": {},
   "source": [
    "# Evaluation Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f39f5e",
   "metadata": {},
   "source": [
    "In recommendation problems, the goal is not to predict exact rating values but to rank items so that relevant ones appear in a user’s top suggestions. Because the Food.com dataset is very sparse and ratings are heavily skewed toward high values, traditional regression-style metrics such as RMSE or MAE are not meaningful. They depend on predicting accurate numeric ratings and are dominated by the dataset’s skewed distribution.\n",
    "\n",
    "Instead, we evaluate models using top-K ranking metrics computed on held-out user interactions in the validation set. These metrics measure how effectively a recommender retrieves items the user actually interacted with, which directly reflects the practical goal of a recipe recommender system.\n",
    "\n",
    "We use four standard ranking metrics:\n",
    "\n",
    "- **Precision@K** — the fraction of recommended items in the top-K that the user actually interacted with. Measures recommendation accuracy.\n",
    "\n",
    "- **Recall@K** — the fraction of the user’s relevant items that appear in the top-K. Measures coverage of true preferences.\n",
    "\n",
    "- **MRR (Mean Reciprocal Rank)** — evaluates how early the first relevant item appears in the recommendation list.\n",
    "\n",
    "- **AUC (Area Under the ROC Curve)** — measures how well the model ranks positive items ahead of unobserved ones, accounting for overall ranking quality.\n",
    "\n",
    "Together, these metrics give a robust picture of recommendation quality: accuracy of the top-K list (Precision), ability to retrieve most of the user’s relevant items (Recall), ranking sharpness (MRR), and global discrimination ability (AUC). These metrics are standard in information retrieval and recommender systems and do not rely on rating magnitude, making them well-suited to implicit feedback data.\n",
    "\n",
    "All models developed later in the notebook (e.g., improved similarity functions or alternative baselines) will be evaluated using this same framework for consistent comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "102e9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Ranking Metrics for Recipe Recommendation\n",
    "# ==============================================================\n",
    "\n",
    "def precision_at_k(recommended, relevant, k=10):\n",
    "    \"\"\"\n",
    "    Precision@K = (# of recommended items in top-K that are relevant) / K\n",
    "    recommended: list of item_ids (ranked)\n",
    "    relevant: set of ground-truth item_ids\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return 0.0\n",
    "    recommended_at_k = recommended[:k]\n",
    "    hits = sum(1 for item in recommended_at_k if item in relevant)\n",
    "    return hits / k\n",
    "\n",
    "\n",
    "def recall_at_k(recommended, relevant, k=10):\n",
    "    \"\"\"\n",
    "    Recall@K = (# of recommended items in top-K that are relevant) / (# relevant items)\n",
    "    \"\"\"\n",
    "    if len(relevant) == 0:\n",
    "        return 0.0\n",
    "    recommended_at_k = recommended[:k]\n",
    "    hits = sum(1 for item in recommended_at_k if item in relevant)\n",
    "    return hits / len(relevant)\n",
    "\n",
    "\n",
    "def mrr(recommended, relevant):\n",
    "    \"\"\"\n",
    "    Mean Reciprocal Rank = 1 / rank of first relevant item (if any)\n",
    "    \"\"\"\n",
    "    for rank, item in enumerate(recommended, start=1):\n",
    "        if item in relevant:\n",
    "            return 1.0 / rank\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def auc_score(recommended, relevant, all_items, num_neg_samples=100):\n",
    "    \"\"\"\n",
    "    Sampled AUC computed using sklearn's roc_auc_score.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    recommended : list\n",
    "        Ranked list of recommended item_ids (best items first).\n",
    "    relevant : set or list\n",
    "        Ground-truth positive items for the user (from val_df).\n",
    "    all_items : set\n",
    "        Universe of item_ids (train + val).\n",
    "    num_neg_samples : int\n",
    "        Number of negative items to sample for AUC estimation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Sampled AUC score.\n",
    "    \"\"\"\n",
    "    relevant = set(relevant)\n",
    "\n",
    "    # Universe of negative items\n",
    "    non_relevant = list(all_items - relevant)\n",
    "    if len(relevant) == 0 or len(non_relevant) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Sample a subset of negatives\n",
    "    sampled_neg = random.sample(non_relevant, min(num_neg_samples, len(non_relevant)))\n",
    "\n",
    "    # Construct y_true (1 = relevant, 0 = negative)\n",
    "    y_true = np.array([1] * len(relevant) + [0] * len(sampled_neg))\n",
    "\n",
    "    # Map items to ranks (lower rank is better)\n",
    "    # Items not in recommended get rank = large number\n",
    "    max_rank = len(recommended)\n",
    "    ranks = {item: idx for idx, item in enumerate(recommended)}\n",
    "\n",
    "    def score(item):\n",
    "        # Higher score = more relevant\n",
    "        return -(ranks.get(item, max_rank + 1))\n",
    "\n",
    "    # Score vectors\n",
    "    y_scores = np.array([score(i) for i in relevant] + \n",
    "                        [score(j) for j in sampled_neg])\n",
    "\n",
    "    # sklearn AUC\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_scores)\n",
    "    except ValueError:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38cca7c",
   "metadata": {},
   "source": [
    "# Item–Item Jaccard Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c0258d",
   "metadata": {},
   "source": [
    "We build a simple recommender using item–item collaborative filtering on implicit feedback. Item–item CF is preferred here because users have very few ratings, while items have more interactions, making item overlaps more reliable and scalable.\n",
    "\n",
    "Since Food.com ratings are heavily skewed toward 4–5 stars, we convert explicit ratings into implicit likes (rating ≥ threshold). This removes noise from low/mid ratings and yields cleaner co-occurrence patterns.\n",
    "\n",
    "For similarity, we use Jaccard similarity, which measures the overlap in users who liked two items. Jaccard works well under high sparsity, ignores skewed rating magnitudes, and is efficient to compute using set intersections. Other metrics (cosine, Pearson, Euclidean) are less stable here due to extremely sparse and biased rating vectors.\n",
    "\n",
    "To keep computation efficient, we avoid a full item–item similarity matrix. Instead, for each user, we generate a small candidate set of items co-liked by users with similar interactions and compute Jaccard only within this set.\n",
    "\n",
    "Scores are computed by summing Jaccard similarities between each candidate item and the items the user liked, then returning the top-K unseen items.\n",
    "\n",
    "This provides a clear, interpretable, and fast baseline recommender that we can later tune or extend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 1. Build binary interactions with adjustable threshold\n",
    "# ------------------------------------------------\n",
    "\n",
    "def make_binary_interactions(train_df, threshold=4):\n",
    "    \"\"\"\n",
    "    Convert explicit ratings to implicit binary likes (rating >= threshold).\n",
    "    Returns:\n",
    "        user_likes: dict {user_id -> set of liked item_ids}\n",
    "        item_likes: dict {item_id -> set of users who liked it}\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter to positive interactions only\n",
    "    pos_df = train_df[train_df[\"rating\"] >= threshold]\n",
    "\n",
    "    user_likes = defaultdict(set)\n",
    "    item_likes = defaultdict(set)\n",
    "\n",
    "    for u, i in zip(pos_df[\"user_id\"], pos_df[\"recipe_id\"]):\n",
    "        user_likes[u].add(i)\n",
    "        item_likes[i].add(u)\n",
    "\n",
    "    return user_likes, item_likes\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Jaccard similarity between two items (fast)\n",
    "# ------------------------------------------------\n",
    "\n",
    "def jaccard_similarity(users_i, users_j):\n",
    "    \"\"\"\n",
    "    Jaccard similarity between sets of users who liked item i and item j.\n",
    "    \"\"\"\n",
    "    if not users_i or not users_j:\n",
    "        return 0.0\n",
    "    inter = len(users_i & users_j)\n",
    "    union = len(users_i | users_j)\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Get candidate items for a user\n",
    "# ------------------------------------------------\n",
    "\n",
    "def get_candidate_items(user_id, user_likes, item_likes):\n",
    "    \"\"\"\n",
    "    All items co-liked by any user who liked at least one item in user_likes[user_id].\n",
    "    This reduces computation dramatically compared to full item space.\n",
    "    \"\"\"\n",
    "    candidates = set()\n",
    "    for item in user_likes[user_id]:\n",
    "        for u in item_likes[item]:                 # users who liked this item\n",
    "            candidates |= user_likes[u]            # everything those users liked\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4. Recommend top-K items using sum of Jaccard similarities\n",
    "# ------------------------------------------------\n",
    "\n",
    "def recommend_jaccard(user_id, user_likes, item_likes, top_k=200, max_candidates=5000):\n",
    "    \"\"\"\n",
    "    More balanced Jaccard CF recommender:\n",
    "    - No per-item truncation (preserves co-like signal)\n",
    "    - Limit only final candidate set size (prevents explosion)\n",
    "    \"\"\"\n",
    "\n",
    "    if user_id not in user_likes or len(user_likes[user_id]) == 0:\n",
    "        return []\n",
    "\n",
    "    liked_items = user_likes[user_id]\n",
    "\n",
    "    # Build candidate set\n",
    "    candidate_items = set()\n",
    "    for item in liked_items:\n",
    "        for u in item_likes[item]:\n",
    "            candidate_items |= user_likes[u]\n",
    "\n",
    "    # Remove items user already liked\n",
    "    candidate_items -= liked_items\n",
    "\n",
    "    # Truncate large candidate sets (but only after full construction)\n",
    "    if len(candidate_items) > max_candidates:\n",
    "        candidate_items = set(random.sample(list(candidate_items), max_candidates))\n",
    "\n",
    "    # Score candidates\n",
    "    scores = {}\n",
    "    for c in candidate_items:\n",
    "        score = 0.0\n",
    "        users_c = item_likes[c]\n",
    "        for i in liked_items:\n",
    "            score += jaccard_similarity(item_likes[i], users_c)\n",
    "        scores[c] = score\n",
    "\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [item for item, score in ranked[:top_k]]\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 5. Build model from train_df\n",
    "# ------------------------------------------------\n",
    "\n",
    "THRESHOLD = 4           # adjustable threshold\n",
    "user_likes, item_likes = make_binary_interactions(train_df, threshold=THRESHOLD)\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# Minimal, decoupled inspection helpers\n",
    "# ===========================================================\n",
    "\n",
    "def show_user_likes(user_id, train_df, raw_recipes, threshold=4, max_items=10):\n",
    "    df = (train_df[(train_df[\"user_id\"] == user_id) & (train_df[\"rating\"] >= threshold)]\n",
    "          .sort_values(\"rating\", ascending=False)\n",
    "          .head(max_items))\n",
    "    return df.merge(raw_recipes[[\"id\", \"name\"]], left_on=\"recipe_id\", right_on=\"id\")\n",
    "\n",
    "def show_recommendations(recipe_ids, train_df, raw_recipes, max_items=10):\n",
    "    stats = (train_df[train_df[\"recipe_id\"].isin(recipe_ids)]\n",
    "             .groupby(\"recipe_id\")[\"rating\"].agg([\"count\", \"mean\"]).reset_index())\n",
    "    return stats.merge(raw_recipes[[\"id\", \"name\"]], left_on=\"recipe_id\", right_on=\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea8c7e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385180</td>\n",
       "      <td>77585</td>\n",
       "      <td>2006-11-18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17498</td>\n",
       "      <td>166441</td>\n",
       "      <td>77585</td>\n",
       "      <td>copycat olive garden minestrone soup by todd w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>385180</td>\n",
       "      <td>114506</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17498</td>\n",
       "      <td>21940</td>\n",
       "      <td>114506</td>\n",
       "      <td>blue baby shower punch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>385180</td>\n",
       "      <td>15688</td>\n",
       "      <td>2007-11-24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17498</td>\n",
       "      <td>81738</td>\n",
       "      <td>15688</td>\n",
       "      <td>white trash candy snack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>385180</td>\n",
       "      <td>147335</td>\n",
       "      <td>2008-07-06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17498</td>\n",
       "      <td>78435</td>\n",
       "      <td>147335</td>\n",
       "      <td>chipotle copycat lime rice recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>385180</td>\n",
       "      <td>16746</td>\n",
       "      <td>2008-12-24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17498</td>\n",
       "      <td>45632</td>\n",
       "      <td>16746</td>\n",
       "      <td>mom s gingersnaps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id        date  rating      u       i      id  \\\n",
       "0   385180      77585  2006-11-18     5.0  17498  166441   77585   \n",
       "1   385180     114506  2009-01-03     5.0  17498   21940  114506   \n",
       "2   385180      15688  2007-11-24     4.0  17498   81738   15688   \n",
       "3   385180     147335  2008-07-06     4.0  17498   78435  147335   \n",
       "4   385180      16746  2008-12-24     4.0  17498   45632   16746   \n",
       "\n",
       "                                                name  \n",
       "0  copycat olive garden minestrone soup by todd w...  \n",
       "1                             blue baby shower punch  \n",
       "2                            white trash candy snack  \n",
       "3                  chipotle copycat lime rice recipe  \n",
       "4                                  mom s gingersnaps  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13762</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13762</td>\n",
       "      <td>cheddar crust granny smith apple pie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14083</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14083</td>\n",
       "      <td>toasted swiss   ham sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16494</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16494</td>\n",
       "      <td>lemon icebox cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19027</td>\n",
       "      <td>3</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>19027</td>\n",
       "      <td>ice cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20995</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20995</td>\n",
       "      <td>bittersweet grand marnier chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22161</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22161</td>\n",
       "      <td>marble squares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64363</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>64363</td>\n",
       "      <td>fettuccine with prosciutto  peas and peppers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99456</td>\n",
       "      <td>5</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>99456</td>\n",
       "      <td>country scalloped potatoes   ham  crock pot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>106442</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>106442</td>\n",
       "      <td>chocolate cake brownies with splenda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>122507</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>122507</td>\n",
       "      <td>strawberry chantilly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id  count      mean      id  \\\n",
       "0      13762      1  4.000000   13762   \n",
       "1      14083      1  5.000000   14083   \n",
       "2      16494      1  4.000000   16494   \n",
       "3      19027      3  3.333333   19027   \n",
       "4      20995      1  5.000000   20995   \n",
       "5      22161      2  4.000000   22161   \n",
       "6      64363      1  5.000000   64363   \n",
       "7      99456      5  3.200000   99456   \n",
       "8     106442      1  4.000000  106442   \n",
       "9     122507      1  4.000000  122507   \n",
       "\n",
       "                                           name  \n",
       "0          cheddar crust granny smith apple pie  \n",
       "1                  toasted swiss   ham sandwich  \n",
       "2                          lemon icebox cookies  \n",
       "3                                     ice cream  \n",
       "4             bittersweet grand marnier chicken  \n",
       "5                                marble squares  \n",
       "6  fettuccine with prosciutto  peas and peppers  \n",
       "7   country scalloped potatoes   ham  crock pot  \n",
       "8          chocolate cake brownies with splenda  \n",
       "9                          strawberry chantilly  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example Usage\n",
    "\n",
    "sample_user = random.choice(list(user_likes.keys()))\n",
    "recs = recommend_jaccard(sample_user, user_likes, item_likes, top_k=10)\n",
    "\n",
    "display(show_user_likes(sample_user, train_df, raw_recipes))\n",
    "display(show_recommendations(recs, train_df, raw_recipes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f43f5b",
   "metadata": {},
   "source": [
    "## Evaluation of the Jaccard Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ebcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 1000 users for Precision/Recall/MRR...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision@5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall@5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision@10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall@10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision@20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall@20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MRR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Metric  Score\n",
       "0   Precision@5    0.0\n",
       "1      Recall@5    0.0\n",
       "2  Precision@10    0.0\n",
       "3     Recall@10    0.0\n",
       "4  Precision@20    0.0\n",
       "5     Recall@20    0.0\n",
       "6           MRR    0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# Evaluate Jaccard Baseline on val_df (Precision, Recall, MRR)\n",
    "# ===========================================================\n",
    "\n",
    "# 1. Build ground-truth interactions\n",
    "val_user_truth = defaultdict(set)\n",
    "for u, i in zip(val_df[\"user_id\"], val_df[\"recipe_id\"]):\n",
    "    val_user_truth[u].add(i)\n",
    "\n",
    "# 2. Define ranking metrics\n",
    "Ks = [5, 10, 20]\n",
    "\n",
    "results = { \n",
    "    \"precision\": {k: [] for k in Ks},\n",
    "    \"recall\":    {k: [] for k in Ks},\n",
    "    \"mrr\": []\n",
    "}\n",
    "\n",
    "# 3. Sample validation users for efficiency\n",
    "NUM_USERS_FOR_RANKING = 1000  # adjust: 500–1500 is typical\n",
    "all_val_users = list(val_user_truth.keys())\n",
    "users_to_eval = random.sample(all_val_users, min(NUM_USERS_FOR_RANKING, len(all_val_users)))\n",
    "\n",
    "print(f\"Evaluating {len(users_to_eval)} users for Precision/Recall/MRR...\\n\")\n",
    "\n",
    "# 4. Evaluation loop (fast)\n",
    "for user in users_to_eval:\n",
    "\n",
    "    # User must have training data\n",
    "    if user not in user_likes or len(user_likes[user]) == 0:\n",
    "        continue\n",
    "    \n",
    "    relevant = val_user_truth[user]\n",
    "    recs = recommend_jaccard(user, user_likes, item_likes, top_k=200)\n",
    "    \n",
    "    # Precision & Recall\n",
    "    for k in Ks:\n",
    "        results[\"precision\"][k].append( precision_at_k(recs, relevant, k=k) )\n",
    "        results[\"recall\"][k].append( recall_at_k(recs, relevant, k=k) )\n",
    "        \n",
    "    # MRR\n",
    "    results[\"mrr\"].append( mrr(recs, relevant) )\n",
    "\n",
    "# 5. Aggregate into summary (no AUC yet)\n",
    "summary_rows = []\n",
    "\n",
    "for k in Ks:\n",
    "    summary_rows.append({\n",
    "        \"Metric\": f\"Precision@{k}\",\n",
    "        \"Score\": np.mean(results[\"precision\"][k])\n",
    "    })\n",
    "    summary_rows.append({\n",
    "        \"Metric\": f\"Recall@{k}\",\n",
    "        \"Score\": np.mean(results[\"recall\"][k])\n",
    "    })\n",
    "\n",
    "summary_rows.append({\n",
    "    \"Metric\": \"MRR\",\n",
    "    \"Score\": np.mean(results[\"mrr\"])\n",
    "})\n",
    "\n",
    "jaccard_summary_partial = pd.DataFrame(summary_rows)\n",
    "jaccard_summary_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab20bf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision@5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall@5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision@10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall@10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision@20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall@20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MRR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUC (sampled users)</td>\n",
       "      <td>0.499449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Metric     Score\n",
       "0          Precision@5  0.000000\n",
       "1             Recall@5  0.000000\n",
       "2         Precision@10  0.000000\n",
       "3            Recall@10  0.000000\n",
       "4         Precision@20  0.000000\n",
       "5            Recall@20  0.000000\n",
       "6                  MRR  0.000000\n",
       "7  AUC (sampled users)  0.499449"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# Compute Sampled AUC for Jaccard Baseline (Subset of Users)\n",
    "# ===========================================================\n",
    "\n",
    "NUM_USERS_FOR_AUC = 400  # adjust as needed\n",
    "\n",
    "# Universe of items\n",
    "all_items = set(train_df[\"recipe_id\"].unique()) | set(val_df[\"recipe_id\"].unique())\n",
    "\n",
    "# Randomly sample users for AUC\n",
    "users_for_auc = random.sample(\n",
    "    list(val_user_truth.keys()),\n",
    "    min(NUM_USERS_FOR_AUC, len(val_user_truth))\n",
    ")\n",
    "\n",
    "auc_scores = []\n",
    "\n",
    "for user in users_for_auc:\n",
    "    if user not in user_likes or len(user_likes[user]) == 0:\n",
    "        continue\n",
    "        \n",
    "    relevant = val_user_truth[user]\n",
    "    recs = recommend_jaccard(user, user_likes, item_likes, top_k=200)\n",
    "    \n",
    "    auc_scores.append( auc_score(recs, relevant, all_items) )\n",
    "\n",
    "# Add to summary\n",
    "auc_row = {\n",
    "    \"Metric\": \"AUC (sampled users)\",\n",
    "    \"Score\": np.mean(auc_scores) if auc_scores else 0.0\n",
    "}\n",
    "\n",
    "jaccard_summary = pd.concat(\n",
    "    [jaccard_summary_partial, pd.DataFrame([auc_row])],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "jaccard_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97d9f169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_count = sum(\n",
    "    1 for items in val_user_truth.values()\n",
    "    for i in items\n",
    "    if i in item_likes\n",
    ")\n",
    "\n",
    "overlap_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ee9a7",
   "metadata": {},
   "source": [
    "### Challenges in Applying Item–Item Jaccard Collaborative Filtering to the Food.com Dataset\n",
    "\n",
    "When evaluating a simple item–item recommender based on **Jaccard similarity** over implicit feedback, we observed that all ranking metrics (Precision@K, Recall@K, and MRR) were exactly zero, and AUC hovered around 0.5 (random performance). After investigating the data and our preprocessing pipeline, we found that this behavior stems from fundamental characteristics of the Food.com dataset and the limitations of item–item Jaccard CF, rather than from an implementation error.\n",
    "\n",
    "#### 1. Extreme Item Sparsity and Lack of Co-Rating Signal\n",
    "The Food.com dataset contains over 230,000 unique recipes, but most recipes are rated by only a single user. This results in:\n",
    "- Very few items sharing more than one user.\n",
    "- Many items sharing **no** users with any other item.\n",
    "- An item–item graph that is essentially disconnected.\n",
    "\n",
    "Since Jaccard similarity relies on overlapping user sets to establish item similarity, the model is unable to form meaningful relationships between most recipes.\n",
    "\n",
    "#### 2. No Overlap Between Training and Validation Items\n",
    "A critical diagnostic showed that **none of the recipes appearing in the validation set also appear in the training set’s implicit “likes” graph**. Even after lowering the implicit-feedback threshold to include *all* ratings (rating ≥ 0), the overlap remained zero.  \n",
    "If a validation item never appears among the items in the training graph, then **no item-based CF model can ever recommend it**, making non-zero Precision/Recall/MRR impossible.\n",
    "\n",
    "#### 3. Consequences of Random Train/Validation Splitting\n",
    "Because the train/validation split was randomized, many items that appear only once in the entire dataset happened to fall into the validation set. These items therefore disappear from the training interactions entirely. In sparse recommendation settings, random splits destroy the item–item co-occurrence structure required for collaborative filtering models to function.\n",
    "\n",
    "#### 4. Why AUC ≈ 0.5\n",
    "AUC measures the probability that a relevant item scores higher than a non-relevant one. If the model never ranks relevant items at all—and assigns only default or noise-driven scores—then the positive-vs-negative comparisons effectively become random, producing an AUC near 0.5.\n",
    "\n",
    "#### Summary\n",
    "Taken together, these challenges mean that **item–item Jaccard collaborative filtering is not viable on this dataset with the current preprocessing and split strategy**. The sparsity of interactions, the near-complete absence of co-liked items, and the lack of training–validation item overlap make it impossible for the model to retrieve held-out items. This motivates the use of alternative baselines (e.g., popularity) or different modeling approaches (e.g., user–user similarity or embedding-based methods) that are more robust under extreme sparsity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2226f7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    160901.000000\n",
       "mean          4.343671\n",
       "std          13.421461\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           2.000000\n",
       "75%           4.000000\n",
       "max        1091.000000\n",
       "Name: user_id, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_counts = train_df.groupby(\"recipe_id\")[\"user_id\"].nunique()\n",
    "item_user_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d6a1e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(94423), np.int64(66478))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_multi_user_items = (item_user_counts > 1).sum()\n",
    "num_single_user_items = (item_user_counts == 1).sum()\n",
    "\n",
    "num_multi_user_items, num_single_user_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e0fbe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6621, 160901)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_items = set(val_df[\"recipe_id\"].unique())\n",
    "train_items = set(train_df[\"recipe_id\"].unique())\n",
    "\n",
    "len(val_items & train_items), len(val_items), len(train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea09b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
